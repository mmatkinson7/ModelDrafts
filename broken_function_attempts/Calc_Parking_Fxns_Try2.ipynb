{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1850af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pysal\n",
    "from osgeo import gdal\n",
    "import copy\n",
    "import libpysal as lps\n",
    "import scipy\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a122b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in data\n",
    "base = \"J:\\\\Shared drives\\\\TMD_TSA\\\\Data\\\\Parking\\\\WebScraped_ParkingCost\\\\required_inputs\"\n",
    "# parking costs\n",
    "rates = pd.read_csv(base+\"\\parking_cost_fullrec_NAP_F16.csv\")\n",
    "\n",
    "# spatial points\n",
    "points = gpd.read_file(base+\"\\GeocodedParkingLots\\DKedits_parking_cost_fullrec_NAP.shp\")\n",
    "points = points.dropna(subset=[\"geometry\"])\n",
    "\n",
    "# join cost to points\n",
    "lots = points[['IN_SingleL','geometry','USER_month','USER_lot_u']].merge(rates[['IN_SingleLine','USER_lot_url',\n",
    "                                                                                'MR','DR','HR']],\n",
    "                                                                         left_on='USER_lot_u',right_on='USER_lot_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac57b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in relevant TAZs\n",
    "base2 = \"J:\\Shared drives\\TMD_TSA\\Data\\GIS Data\\TAZ\"\n",
    "alltazs = gpd.read_file(base2+\"\\\\candidate_CTPS_TAZ_STATEWIDE_2019_wgs84.shp\")\n",
    "#alltazs = alltazs[(alltazs['town'].isin([\"BOSTON\",\"CAMBRIDGE\",\"SOMERVILLE\",\"BROOKLINE\",\"NEWTON\"])) & (\n",
    "    #alltazs['id'] < 200000) & \n",
    "    #~(alltazs['id'].isin([397,398,399]))][[\"id\",\"town\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f190857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_parking_costs(mr,dr,hr,mdr,dhr,mhr,elots):\n",
    "    # filter out customer only parking (no rates for any category)\n",
    "    estmonth = lots[(~lots['MR'].isna()) | (~lots['DR'].isna()) | (~lots['HR'].isna())].to_crs(\"EPSG:4326\")\n",
    "    # 1. Calculate ratios\n",
    "    estmonth[mdr] = np.where(estmonth[dr] == 0,None,estmonth[mr]/estmonth[dr])\n",
    "    estmonth[dhr] = np.where(estmonth[hr] == 0,None,estmonth[dr]/estmonth[hr])\n",
    "    estmonth[mhr] = estmonth[dhr]*estmonth[mdr]\n",
    "    \n",
    "    # 2. Multiply sample rates by means of ratios\n",
    "    estmonth['Est_'+mr] = estmonth[dr] * estmonth[mdr].mean()\n",
    "    estmonth['Est_'+dr] = estmonth[hr] * estmonth[dhr].mean()\n",
    "    estmonth['Est_'+hr] = estmonth[mr] / estmonth[mhr].mean()\n",
    "    \n",
    "    # 3. Create a new field containing sample data if exists, otherwise use estimated value\n",
    "    for tp in [mr, dr, hr]:\n",
    "        estmonth[tp+'_wEst'] = np.where(estmonth[tp].isna(),estmonth['Est_'+tp],estmonth[tp])\n",
    "    \n",
    "    # 4. Do it again!        \n",
    "    estmonth['Est_'+mr+'2'] = estmonth[dr+'_wEst'] * estmonth[mdr].mean()\n",
    "    estmonth['Est_'+dr+'2'] = estmonth[hr+'_wEst'] * estmonth[dhr].mean()\n",
    "    estmonth['Est_'+hr+'2'] = estmonth[mr+'_wEst'] / estmonth[mhr].mean()\n",
    "\n",
    "    for tp in [mr, dr, hr]:\n",
    "        estmonth[tp+'_wEst2'] = np.where(estmonth[tp+'_wEst'].isna(),estmonth['Est_'+tp+'2'],estmonth[tp+'_wEst'])\n",
    "\n",
    "    return estmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be24828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estmonth = estimate_parking_costs(\"MR\",\"DR\",\"HR\",\"Monthly_to_Daily\",\"Daily_to_Hourly\",\"Monthly_to_Hourly\",lots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ee145",
   "metadata": {},
   "outputs": [],
   "source": [
    "estmonth.to_csv(\"J:\\Shared drives\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\estmonth_update.csv\")\n",
    "estmonth.to_file(\"J:\\Shared drives\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\estmonth_update.geojson\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8959d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE RESULTS OF LOCAL MORAN's I\n",
    "estmonth = gpd.read_file(\"J:\\\\Shared drives\\\\TMD_TSA\\\\Data\\\\Parking\\\\WebScraped_ParkingCost\\\\tazs_avg_rates2010_barf.geojson\")\n",
    "estmonth = estmonth.drop(columns=[\"index\"])\n",
    "#estmonthLM = gpd.read_file(\"J:\\Shared drives\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\\\required_inputs\\estmonth_April14_HR_DR_MR_LM.geojson\")\n",
    "#estmonth = estmonth.to_crs(estmonthLM.crs)\n",
    "\n",
    "#estmonth = estmonth.drop(columns=[\"index_right\"])\n",
    "#estmonth = estmonth.sjoin_nearest(estmonthLM[[\"COType_HR\",\"COType_DR\",\"COType_MR\",\"geometry\"]], how=\"left\")\n",
    "\n",
    "# 1 and 13 are very close to each other (see index_right) removing them so can filter later\n",
    "estmonth = estmonth[~estmonth.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cfeac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get euclidean distance matrix from TAZ centroids to lots\n",
    "# also reproject to Mass State Plane (meters) so that distance is correct\n",
    "rdg83 = alltazs.to_crs(\"EPSG:26986\").set_index(\"id\") # TAZ ids are now the column names\n",
    "estmonth83 = estmonth.to_crs(\"EPSG:26986\") # index is the row name\n",
    "\n",
    "eucdist = estmonth83.centroid.geometry.apply(lambda g: rdg83.distance(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709b216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to miles\n",
    "lpt = {}\n",
    "eucdistmi = eucdist/1609.34\n",
    "# get just closest 16 lots to each TAZ centroid based on euclidean distance\n",
    "numlot = len(eucdistmi)\n",
    "for col in eucdistmi.columns:\n",
    "    big8 = max(eucdistmi[col].nsmallest(16))\n",
    "    eucdistmi.loc[eucdistmi[col] > big8, col]= np.nan\n",
    "    lpt[col] = eucdistmi[eucdistmi[col] <= big8][col].index\n",
    "# set distances (weights) to 1 so all have equal weights\n",
    "eucdistmi[eucdistmi.notna()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cec28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tazids = alltazs[(alltazs['town'].isin([\"BOSTON\",\"CAMBRIDGE\",\"SOMERVILLE\",\n",
    "                                        \"BROOKLINE\",\"NEWTON\"])) & (alltazs['id'] < 200000)][\"id\"].tolist()\n",
    "\n",
    "# get lot ids where HL or LH for each time period and exclude them from the weighted average\n",
    "hr_in = estmonth[~estmonth['COType_HR'].isin([\"LH\", \"HL\"])].reset_index()['index']\n",
    "mr_in = estmonth[~estmonth['COType_MR'].isin([\"LH\", \"HL\"])].reset_index()['index']\n",
    "dr_in = estmonth[~estmonth['COType_DR'].isin([\"LH\", \"HL\"])].reset_index()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dfca496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weighted average\n",
    "\n",
    "# 1. multiply weights (1) by rates\n",
    "# filter the rates by whether the lot is an outlier - so will match weights below\n",
    "hr = estmonth[\"Hourly_Rate_wEst2\"].filter(items = hr_in, axis=0)\n",
    "dr = estmonth[\"Daily_Rate_wEst2\"].filter(items = dr_in, axis=0)\n",
    "mr = estmonth[\"Monthly_Rate_wEst2\"].filter(items = mr_in, axis=0)\n",
    "\n",
    "# filter the weights by whether the lot is an outlier, then multiply by rates\n",
    "xWhr = eucdistmi.filter(items = hr_in, axis=0).multiply(hr, axis=\"index\")\n",
    "xWdr = eucdistmi.filter(items = dr_in, axis=0).multiply(dr, axis=\"index\")\n",
    "xWmr = eucdistmi.filter(items = mr_in, axis=0).multiply(mr, axis=\"index\")\n",
    "\n",
    "# sum weighted rates by TAZ\n",
    "xW_hr_taz = xWhr.sum()\n",
    "xW_dr_taz = xWdr.sum()\n",
    "xW_mr_taz = xWmr.sum()\n",
    "xW_hr_taz.name = \"HRSum16\"\n",
    "xW_dr_taz.name = \"DRSum16\"\n",
    "xW_mr_taz.name = \"MRSum16\"\n",
    "\n",
    "#sum weights by TAZ\n",
    "W_taz = eucdistmi.sum()\n",
    "W_taz.name = \"TotalNN\"\n",
    "\n",
    "# join weighted rates sums by taz and sum weights by taz together\n",
    "wAvg = pd.merge(W_taz,xW_hr_taz, left_index=True, right_index=True)\n",
    "wAvg = pd.merge(wAvg,xW_dr_taz, left_index=True, right_index=True)\n",
    "wAvg = pd.merge(wAvg,xW_mr_taz, left_index=True, right_index=True)\n",
    "\n",
    "# set weighted average rates to 0 where TAZ not in prediction area\n",
    "wAvg[\"HRSum16\"] = np.where(~wAvg.index.isin(tazids), 0, wAvg[\"HRSum16\"])\n",
    "wAvg[\"DRSum16\"] = np.where(~wAvg.index.isin(tazids), 0, wAvg[\"DRSum16\"])\n",
    "wAvg[\"MRSum16\"] = np.where(~wAvg.index.isin(tazids), 0, wAvg[\"MRSum16\"])\n",
    "\n",
    "wAvg[\"NN_Average_HR\"] = wAvg[\"HRSum16\"]/wAvg[\"TotalNN\"]\n",
    "wAvg[\"NN_Average_DR\"] = wAvg[\"DRSum16\"]/wAvg[\"TotalNN\"]\n",
    "wAvg[\"NN_Average_MR\"] = wAvg[\"MRSum16\"]/wAvg[\"TotalNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68d9c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "tazs_avg_rates = pd.merge(rdg83,wAvg, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5f439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tazs_avg_rates.to_file(\"J:\\Shared drives\\\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\\\tazs_avg_rates_updated.geojson\")  \n",
    "tazs_avg_rates.drop(\"geometry\",axis=1).to_csv(\"J:\\\\Shared drives\\\\TMD_TSA\\\\Data\\\\Parking\\\\WebScraped_ParkingCost\\\\tazs_avg_rates_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geostat] *",
   "language": "python",
   "name": "conda-env-geostat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
