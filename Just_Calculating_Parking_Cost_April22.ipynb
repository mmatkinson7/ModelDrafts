{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2391a7",
   "metadata": {},
   "source": [
    "# DOES NOT YET GIVE SAME RESULTS AS CORRECT PARKING_COST_APRIL22.IPYNB\n",
    "\n",
    "\n",
    "# Estimating Parking Cost and Spatial Autocorrelation Analysis of Parking Data\n",
    "\n",
    "Goals:\n",
    "   1. Join csv cost data with spatial data for parking lots\n",
    "   3. Estimate Ratios of M to D, D to H, M to H to estimate missing rates values.\n",
    "   4. KNN for points to polygons (TAZs)\n",
    "\n",
    "For inflation adjustment: https://www.inflationtool.com/us-dollar/2010-to-present-value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dee3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pysal\n",
    "from osgeo import gdal\n",
    "import copy\n",
    "import libpysal as lps\n",
    "import scipy\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffa289",
   "metadata": {},
   "source": [
    "## Bring In Data\n",
    "\n",
    "1. Lot Rates\n",
    "2. Lot Points\n",
    "3. Join Points and Rates\n",
    "4. Filter Lots (must have at least one rate)\n",
    "5. TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62d428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in data\n",
    "base = \"J:\\\\Shared drives\\\\TMD_TSA\\\\Data\\\\Parking\\\\WebScraped_ParkingCost\\\\required_inputs\"\n",
    "# parking costs\n",
    "rates = pd.read_csv(base+\"\\parking_cost_fullrec_NAP_F16.csv\")\n",
    "\n",
    "# spatial points\n",
    "points = gpd.read_file(base+\"\\GeocodedParkingLots\\DKedits_parking_cost_fullrec_NAP.shp\")\n",
    "points = points.dropna(subset=[\"geometry\"])\n",
    "\n",
    "# join cost to points\n",
    "lots = points[['IN_SingleL','geometry','USER_month','USER_lot_u']].merge(rates[['IN_SingleLine','USER_lot_url',\n",
    "                                                                                'MR','DR','HR']],\n",
    "                                                                         left_on='USER_lot_u',right_on='USER_lot_url')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21436fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in relevant TAZs\n",
    "base2 = \"J:\\Shared drives\\TMD_TSA\\Data\\GIS Data\\TAZ\"\n",
    "alltazs = gpd.read_file(base2+\"\\\\candidate_CTPS_TAZ_STATEWIDE_2019_wgs84.shp\")\n",
    "# filter to just relevant municipalities\n",
    "#alltazs = alltazs[(alltazs['town'].isin([\"BOSTON\",\"CAMBRIDGE\",\"SOMERVILLE\",\"BROOKLINE\",\"NEWTON\"])) & (alltazs['id'] < 200000)][[\"id\",\"town\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76d5e0",
   "metadata": {},
   "source": [
    "## Estimate and Fill Missing Monthly Rates\n",
    "\n",
    "Calculate the Monthly/Daily ratio per district by dividing the monthly column by the daily column to get lot level ratios and aggregate to the region. This region-wide ratio is multiplied by each lot's Daily Rate to calculate an estimated monthly rate. At this point, a new column is made where observed monthly rate data unless missing, then estimated monthly rate data is used if existing (aka if lot has a daily rate). \n",
    "\n",
    "This will be conducted for M/D, D/H, and M/H - M/D is used as the example for the explanation for ease of understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a726174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_lot_rates(tps, lots):\n",
    "    # filter out customer only parking (no rates for any category)\n",
    "    estmonth = copy.deepcopy(lots[lots[tps].notna().any(axis='columns')])\n",
    "    #estmonth = copy.deepcopy(lots[(~lots['MR'].isna()) | (~lots['DR'].isna()) | (~lots['HR'].isna())])\n",
    "    \n",
    "    tp2_0 = []\n",
    "    # estimate round 1: lot rate estimations based on other tp values\n",
    "    for tp2 in list(combinations(tps, 2)):\n",
    "        if 'Est_'+tp2[0] in estmonth.columns:\n",
    "            tp2 = tuple(reversed(tp2))\n",
    "            if 'Est_'+tp2[0] in estmonth.columns:\n",
    "                continue # if both are already estimated go to next pair\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        ratio = tp2[0] +'_to_'+tp2[1]\n",
    "        \n",
    "        #get ratio at the lot level\n",
    "        estmonth[ratio] = np.where((estmonth[tp2[1]]== 0) | (estmonth[tp2[0]]== 0), 0,estmonth[tp2[0]]/estmonth[tp2[1]])           \n",
    "        \n",
    "        # estimate monthly from daily and mean regional ratio (using only where both values)\n",
    "        estmonth['Est_'+tp2[0]] = estmonth[tp2[1]] * estmonth[ratio].mean()\n",
    "\n",
    "        # combine estimated daily with actual daily where possible\n",
    "        estmonth[tp2[0]+'_wEst'] = np.where(estmonth[tp2[0]].isna(),\n",
    "                                                 estmonth['Est_'+tp2[0]],\n",
    "                                                 estmonth[tp2[0]])\n",
    "    \n",
    "    # estimate round 2: lot rate estimates based on other estimated values\n",
    "    tp2_0 = []\n",
    "    for tp2 in list(combinations(tps, 2)):\n",
    "        if 'Est_'+tp2[0]+'_2' in estmonth.columns:\n",
    "            tp2 = tuple(reversed(tp2))\n",
    "            if 'Est_'+tp2[0]+'_2' in estmonth.columns:\n",
    "                continue # if both are already re-estimated go to next pair\n",
    "        tp2_0.append(tp2[0])\n",
    "        estmonth['Est_'+tp2[0]+'_2'] = estmonth[tp2[1]+'_wEst'] * estmonth[tp2[0] +'_to_'+tp2[1]].mean()\n",
    "\n",
    "        # combine estimated daily with actual daily where possible\n",
    "        estmonth[tp2[0]+'_wEst2'] = np.where(estmonth[tp2[0]].isna(),\n",
    "                                                 estmonth['Est_'+tp2[0]+'_2'],\n",
    "                                                 estmonth[tp2[0]])\n",
    "    \n",
    "    return estmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4e8405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tps = [\"MR\", \"DR\", \"HR\"]\n",
    "K = 16\n",
    "all_lots = lots\n",
    "all_tazs = alltazs\n",
    "\n",
    "\n",
    "elots = estimate_lot_rates(tps, all_lots)\n",
    "\n",
    "# post LM geojson - only need if running remove_outliers\n",
    "postSAdf = gpd.read_file(base+\"\\estmonth_April14_HR_DR_MR_LM.geojson\")\n",
    "cluster_outlier_field = \"COType_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1174cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTS\n",
    "\n",
    "elots.to_csv(\"J:\\Shared drives\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\estmonth_April25d.csv\")\n",
    "\n",
    "# Export estmonth as geojson for use in ArcPro and QGIS for Local Moran's I and Getis Ord Gi*\n",
    "elots.to_file(\"J:\\Shared drives\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\estmonth_April25d.geojson\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887ffe9",
   "metadata": {},
   "source": [
    "# Calculate Average Rates per TAZ\n",
    "### Post Local Spatial Autocorrelation (Local Moran's I)\n",
    "The data is clustered - see versions of this analysis with Spatial Autocorrelation included for information on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172c8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(lots, postSA, cof):\n",
    "    # if importing new data to add to lots, add and delete outliers\n",
    "    if isinstance(postSA, gpd.GeoDataFrame) and (len(cof) > 0): # if importing new data with LM outliers\n",
    "        postSA = postSA.to_crs(26986)\n",
    "        estmonth = lots.sjoin_nearest(postSA[[cluster_outlier_field+s for s in tps]+[\"geometry\"]], how=\"left\")\n",
    "        \n",
    "        # 1 and 13 are very close to each other (see index_right) removing them so can filter later\n",
    "        estmonth = estmonth[~estmonth.index.duplicated(keep='first')]\n",
    "        \n",
    "        # get lot ids where HL or LH for each time period and exclude them from the weighted average\n",
    "        inin =[]\n",
    "        for x in tps:\n",
    "            inin.append(estmonth[~estmonth[cof+x].isin([\"LH\", \"HL\"])].reset_index()['index']) \n",
    "    return estmonth, inin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb6afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_matrix(lots,tazs,K,tps,inin=[]):\n",
    "\n",
    "    estmonth = copy.deepcopy(lots)\n",
    "    if len(inin) == 0:\n",
    "        for x in tps:\n",
    "            inin.append(estmonth.reset_index['index'])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # get euclidean distance matrix from TAZ centroids to lots\n",
    "    # also reproject to Mass State Plane (meters) so that distance is correct\n",
    "    rdg83 = alltazs.to_crs(\"EPSG:26986\").set_index(\"id\") # TAZ ids are now the column names\n",
    "    estmonth =  estmonth.to_crs(\"EPSG:26986\")\n",
    "    eucdist = estmonth.centroid.geometry.apply(lambda g: rdg83.distance(g))\n",
    "    # convert to miles\n",
    "    eucdistmi = eucdist/1609.34\n",
    "    \n",
    "    # get just closest 16 lots to each TAZ centroid based on euclidean distance\n",
    "    numlot = len(eucdistmi)\n",
    "    for col in eucdistmi.columns:\n",
    "        big = max(eucdistmi[col].nsmallest(K))\n",
    "        eucdistmi.loc[eucdistmi[col] > big, col]= np.nan\n",
    "\n",
    "    # set distances (weights) to 1 so all have equal weights\n",
    "    eucdistmi[eucdistmi.notna()] = 1\n",
    "    \n",
    "    return eucdistmi, inin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d979d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_average(tps, estmonth, eucdistmi, inin, tazs):\n",
    "    # tazs & lots to filter\n",
    "    tazids = tazs[(tazs['town'].isin([\"BOSTON\",\"CAMBRIDGE\",\"SOMERVILLE\",\n",
    "                                        \"BROOKLINE\",\"NEWTON\"])) & (tazs['id'] < 200000)][\"id\"].tolist()\n",
    "    \n",
    "\n",
    "    # multiply weights (1) by rates, reminder: weights are all 1 so this is essentially a mask\n",
    "    # filter the rates and weights by whether the lot is an outlier, then multiply\n",
    "    msums = []\n",
    "    for z in tps:\n",
    "        g = estmonth[z+'_wEst2'].filter(items = inin[tps.index(z)], axis=0)\n",
    "        m = eucdistmi.filter(items = inin[tps.index(z)], axis=0).multiply(g, axis=\"index\")\n",
    "        msum = m.sum()\n",
    "        msum.name = z+\"_SumNN\"\n",
    "        #save so can merge together later\n",
    "        msums.append(msum)\n",
    "        \n",
    "    #sum weights by TAZ\n",
    "    wsum = eucdistmi.sum() # should be K from KNN\n",
    "    wsum.name = \"TotalNN\"\n",
    "    \n",
    "    # join weighted rates sums by taz and sum weights by taz together\n",
    "    for q in msums:\n",
    "        wsum = pd.merge(wsum,q, left_index=True, right_index=True)\n",
    "        wsum[q.name] = np.where(~wsum.index.isin(tazids), 0, wsum[q.name])\n",
    "        wsum[q.name.split(\"_\")[0]+\"_Avg_NN\"] = wsum[q.name]/wsum[\"TotalNN\"]\n",
    "        \n",
    "        # Convert to 2010\n",
    "        wsum[q.name.split(\"_\")[0]+\"_Avg_NN_2010\"] = wsum[q.name.split(\"_\")[0]+\"_Avg_NN\"] * 0.69\n",
    "        \n",
    "    # final spatial result    \n",
    "    tazs_avg_rates = pd.merge(tazs.set_index(\"id\"),wsum, left_index=True, right_index=True)\n",
    "    \n",
    "    return tazs_avg_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c918e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noOutlots, noOutlist = remove_outliers(elots, postSAdf,cluster_outlier_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94be7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distmatrix, noOutlist = euclidean_matrix(noOutlots,all_tazs,K,tps,noOutlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb174ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>taz</th>\n",
       "      <th>type</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>town_state</th>\n",
       "      <th>mpo</th>\n",
       "      <th>in_brmpo</th>\n",
       "      <th>subregion</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalNN</th>\n",
       "      <th>MR_SumNN</th>\n",
       "      <th>MR_Avg_NN</th>\n",
       "      <th>MR_Avg_NN_2010</th>\n",
       "      <th>DR_SumNN</th>\n",
       "      <th>DR_Avg_NN</th>\n",
       "      <th>DR_Avg_NN_2010</th>\n",
       "      <th>HR_SumNN</th>\n",
       "      <th>HR_Avg_NN</th>\n",
       "      <th>HR_Avg_NN_2010</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>MIDDLEBOROUGH</td>\n",
       "      <td>MA</td>\n",
       "      <td>MIDDLEBOROUGH,MA</td>\n",
       "      <td>SRPEDD</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>22284.463348</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>BRIDGEWATER</td>\n",
       "      <td>MA</td>\n",
       "      <td>BRIDGEWATER,MA</td>\n",
       "      <td>OCPC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>18241.697275</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>MA</td>\n",
       "      <td>HALIFAX,MA</td>\n",
       "      <td>OCPC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>17900.674759</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>MIDDLEBOROUGH</td>\n",
       "      <td>MA</td>\n",
       "      <td>MIDDLEBOROUGH,MA</td>\n",
       "      <td>SRPEDD</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>23735.098952</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>I</td>\n",
       "      <td>MARSHFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>MARSHFIELD,MA</td>\n",
       "      <td>BRMPO</td>\n",
       "      <td>1</td>\n",
       "      <td>SSC</td>\n",
       "      <td>19458.111922</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>5835</td>\n",
       "      <td>5834</td>\n",
       "      <td>I</td>\n",
       "      <td>TRURO</td>\n",
       "      <td>MA</td>\n",
       "      <td>TRURO,MA</td>\n",
       "      <td>CCC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>20079.041945</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>5836</td>\n",
       "      <td>5835</td>\n",
       "      <td>I</td>\n",
       "      <td>TRURO</td>\n",
       "      <td>MA</td>\n",
       "      <td>TRURO,MA</td>\n",
       "      <td>CCC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>25698.527422</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>5837</td>\n",
       "      <td>5836</td>\n",
       "      <td>I</td>\n",
       "      <td>PROVINCETOWN</td>\n",
       "      <td>MA</td>\n",
       "      <td>PROVINCETOWN,MA</td>\n",
       "      <td>CCC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2836.977271</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209094</th>\n",
       "      <td>5838</td>\n",
       "      <td>5837</td>\n",
       "      <td>E</td>\n",
       "      <td>KILLINGLY</td>\n",
       "      <td>CT</td>\n",
       "      <td>KILLINGLY,CT</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>6486.571441</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209004</th>\n",
       "      <td>5839</td>\n",
       "      <td>5838</td>\n",
       "      <td>E</td>\n",
       "      <td>DOVER</td>\n",
       "      <td>NH</td>\n",
       "      <td>DOVER,NH</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>3246.012901</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5839 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        OBJECTID   taz type           town state        town_state     mpo  \\\n",
       "id                                                                           \n",
       "4398           1     0    I  MIDDLEBOROUGH    MA  MIDDLEBOROUGH,MA  SRPEDD   \n",
       "2571           2     1    I    BRIDGEWATER    MA    BRIDGEWATER,MA    OCPC   \n",
       "2669           3     2    I        HALIFAX    MA        HALIFAX,MA    OCPC   \n",
       "4392           4     3    I  MIDDLEBOROUGH    MA  MIDDLEBOROUGH,MA  SRPEDD   \n",
       "2641           5    49    I     MARSHFIELD    MA     MARSHFIELD,MA   BRMPO   \n",
       "...          ...   ...  ...            ...   ...               ...     ...   \n",
       "4793        5835  5834    I          TRURO    MA          TRURO,MA     CCC   \n",
       "4795        5836  5835    I          TRURO    MA          TRURO,MA     CCC   \n",
       "4794        5837  5836    I   PROVINCETOWN    MA   PROVINCETOWN,MA     CCC   \n",
       "209094      5838  5837    E      KILLINGLY    CT      KILLINGLY,CT    None   \n",
       "209004      5839  5838    E          DOVER    NH          DOVER,NH    None   \n",
       "\n",
       "        in_brmpo subregion    Shape_Leng  ...  TotalNN MR_SumNN  MR_Avg_NN  \\\n",
       "id                                        ...                                \n",
       "4398           0      None  22284.463348  ...     16.0      0.0        0.0   \n",
       "2571           0      None  18241.697275  ...     16.0      0.0        0.0   \n",
       "2669           0      None  17900.674759  ...     16.0      0.0        0.0   \n",
       "4392           0      None  23735.098952  ...     16.0      0.0        0.0   \n",
       "2641           1       SSC  19458.111922  ...     16.0      0.0        0.0   \n",
       "...          ...       ...           ...  ...      ...      ...        ...   \n",
       "4793           0      None  20079.041945  ...     16.0      0.0        0.0   \n",
       "4795           0      None  25698.527422  ...     16.0      0.0        0.0   \n",
       "4794           0      None   2836.977271  ...     16.0      0.0        0.0   \n",
       "209094         0      None   6486.571441  ...     16.0      0.0        0.0   \n",
       "209004         0      None   3246.012901  ...     16.0      0.0        0.0   \n",
       "\n",
       "        MR_Avg_NN_2010  DR_SumNN  DR_Avg_NN  DR_Avg_NN_2010  HR_SumNN  \\\n",
       "id                                                                      \n",
       "4398               0.0       0.0        0.0             0.0       0.0   \n",
       "2571               0.0       0.0        0.0             0.0       0.0   \n",
       "2669               0.0       0.0        0.0             0.0       0.0   \n",
       "4392               0.0       0.0        0.0             0.0       0.0   \n",
       "2641               0.0       0.0        0.0             0.0       0.0   \n",
       "...                ...       ...        ...             ...       ...   \n",
       "4793               0.0       0.0        0.0             0.0       0.0   \n",
       "4795               0.0       0.0        0.0             0.0       0.0   \n",
       "4794               0.0       0.0        0.0             0.0       0.0   \n",
       "209094             0.0       0.0        0.0             0.0       0.0   \n",
       "209004             0.0       0.0        0.0             0.0       0.0   \n",
       "\n",
       "        HR_Avg_NN  HR_Avg_NN_2010  \n",
       "id                                 \n",
       "4398          0.0             0.0  \n",
       "2571          0.0             0.0  \n",
       "2669          0.0             0.0  \n",
       "4392          0.0             0.0  \n",
       "2641          0.0             0.0  \n",
       "...           ...             ...  \n",
       "4793          0.0             0.0  \n",
       "4795          0.0             0.0  \n",
       "4794          0.0             0.0  \n",
       "209094        0.0             0.0  \n",
       "209004        0.0             0.0  \n",
       "\n",
       "[5839 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar = knn_average(tps,noOutlots,distmatrix,noOutlist, all_tazs)\n",
    "tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60944f",
   "metadata": {},
   "source": [
    "# Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58878839",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar.drop(\"geometry\",axis=1).to_csv(\"J:\\\\Shared drives\\\\TMD_TSA\\\\Data\\\\Parking\\\\WebScraped_ParkingCost\\\\tazs_avg_rates2010_Apr25a.csv\")\n",
    "\n",
    "tar.to_file(\"J:\\Shared drives\\\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\\\tazs_avg_ratesApr25a.geojson\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb8af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geostat] *",
   "language": "python",
   "name": "conda-env-geostat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
