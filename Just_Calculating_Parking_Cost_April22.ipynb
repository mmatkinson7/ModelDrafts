{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2391a7",
   "metadata": {},
   "source": [
    "# Estimating Parking Cost and Spatial Autocorrelation Analysis of Parking Data\n",
    "\n",
    "Goals:\n",
    "   1. Join csv cost data with spatial data for parking lots\n",
    "   3. Estimate Ratios of M to D, D to H, M to H to estimate missing rates values.\n",
    "   4. KNN for points to polygons (TAZs)\n",
    "\n",
    "For inflation adjustment: https://www.inflationtool.com/us-dollar/2010-to-present-value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dee3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pysal\n",
    "from osgeo import gdal\n",
    "import copy\n",
    "import libpysal as lps\n",
    "import scipy\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffa289",
   "metadata": {},
   "source": [
    "## Bring In Data\n",
    "\n",
    "1. Lot Rates\n",
    "2. Lot Points\n",
    "3. Join Points and Rates\n",
    "4. Filter Lots (must have at least one rate)\n",
    "5. TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b62d428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in data\n",
    "base = \"J:\\\\Shared drives\\\\TMD_TSA\\\\Data\\\\Parking\\\\WebScraped_ParkingCost\\\\required_inputs\"\n",
    "# parking costs\n",
    "rates = pd.read_csv(base+\"\\parking_cost_fullrec_NAP_F16.csv\")\n",
    "\n",
    "# spatial points\n",
    "points = gpd.read_file(base+\"\\GeocodedParkingLots\\DKedits_parking_cost_fullrec_NAP.shp\")\n",
    "points = points.dropna(subset=[\"geometry\"])\n",
    "\n",
    "# join cost to points\n",
    "lots = points[['IN_SingleL','geometry','USER_month','USER_lot_u']].merge(rates[['IN_SingleLine','USER_lot_url',\n",
    "                                                                                'MR','DR','HR']],\n",
    "                                                                         left_on='USER_lot_u',right_on='USER_lot_url')\n",
    "# drop lots of columns\n",
    "# reproject for easier mapping (From mass state plane to wgs84)\n",
    "#lots = lots.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# filter out customer only parking (no rates for any category)\n",
    "#lots = lots[(~lots['MR'].isna()) | (~lots['DR'].isna()) | (~lots['HR'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b21436fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in relevant TAZs\n",
    "base2 = \"J:\\Shared drives\\TMD_TSA\\Data\\GIS Data\\TAZ\"\n",
    "alltazs = gpd.read_file(base2+\"\\\\candidate_CTPS_TAZ_STATEWIDE_2019_wgs84.shp\")\n",
    "# filter to just relevant municipalities\n",
    "alltazs = alltazs[(alltazs['town'].isin([\"BOSTON\",\"CAMBRIDGE\",\"SOMERVILLE\",\"BROOKLINE\",\"NEWTON\"])) & (alltazs['id'] < 200000)][[\"id\",\"town\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76d5e0",
   "metadata": {},
   "source": [
    "## Estimate and Fill Missing Monthly Rates\n",
    "\n",
    "Calculate the Monthly/Daily ratio per district by dividing the monthly column by the daily column to get lot level ratios and aggregate to the region. This region-wide ratio is multiplied by each lot's Daily Rate to calculate an estimated monthly rate. At this point, a new column is made where observed monthly rate data unless missing, then estimated monthly rate data is used if existing (aka if lot has a daily rate). \n",
    "\n",
    "This will be conducted for M/D, D/H, and M/H - M/D is used as the example for the explanation for ease of understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a726174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_lot_rates(tps, lots):\n",
    "    # filter out customer only parking (no rates for any category)\n",
    "    estmonth = copy.deepcopy(lots[lots[tps].notna().any(axis='columns')])\n",
    "    \n",
    "    tp2_0 = []\n",
    "    # estimate round 1: lot rate estimations based on other tp values\n",
    "    for tp2 in list(combinations(tps, 2)):\n",
    "        if 'Est_'+tp2[0] in estmonth.columns:\n",
    "            tp2 = tuple(reversed(tp2))\n",
    "            if 'Est_'+tp2[0] in estmonth.columns:\n",
    "                continue # if both are already estimated go to next pair\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        ratio = tp2[0] +'_to_'+tp2[1]\n",
    "        \n",
    "        #get ratio at the lot level\n",
    "        estmonth[ratio] = np.where((estmonth[tp2[1]]== 0) | (estmonth[tp2[0]]== 0), 0,estmonth[tp2[0]]/estmonth[tp2[1]])           \n",
    "        \n",
    "        # estimate monthly from daily and mean regional ratio (using only where both values)\n",
    "        estmonth['Est_'+tp2[0]] = estmonth[tp2[1]] * estmonth[ratio].mean()\n",
    "\n",
    "        # combine estimated daily with actual daily where possible\n",
    "        estmonth[tp2[0]+'_wEst'] = np.where(estmonth[tp2[0]].isna(),\n",
    "                                                 estmonth['Est_'+tp2[0]],\n",
    "                                                 estmonth[tp2[0]])\n",
    "    \n",
    "    # estimate round 2: lot rate estimates based on other estimated values\n",
    "    tp2_0 = []\n",
    "    for tp2 in list(combinations(tps, 2)):\n",
    "        if 'Est_'+tp2[0]+'_2' in estmonth.columns:\n",
    "            tp2 = tuple(reversed(tp2))\n",
    "            if 'Est_'+tp2[0]+'_2' in estmonth.columns:\n",
    "                continue # if both are already re-estimated go to next pair\n",
    "        tp2_0.append(tp2[0])\n",
    "        estmonth['Est_'+tp2[0]+'_2'] = estmonth[tp2[1]+'_wEst'] * estmonth[tp2[0] +'_to_'+tp2[1]].mean()\n",
    "\n",
    "        # combine estimated daily with actual daily where possible\n",
    "        estmonth[tp2[0]+'_wEst2'] = np.where(estmonth[tp2[0]].isna(),\n",
    "                                                 estmonth['Est_'+tp2[0]+'_2'],\n",
    "                                                 estmonth[tp2[0]])\n",
    "    \n",
    "    return estmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc4e8405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tps = [\"MR\", \"DR\", \"HR\"]\n",
    "K = 16\n",
    "all_lots = lots\n",
    "all_tazs = alltazs\n",
    "\n",
    "\n",
    "elots = estimate_lot_rates(tps, all_lots)\n",
    "\n",
    "# post LM geojson - only need if running remove_outliers\n",
    "postSAdf = gpd.read_file(base+\"\\estmonth_April14_HR_DR_MR_LM.geojson\")\n",
    "cluster_outlier_field = \"COType_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTS\n",
    "\n",
    "elots.to_csv(\"J:\\Shared drives\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\estmonth.csv\")\n",
    "\n",
    "# Export estmonth as geojson for use in ArcPro and QGIS for Local Moran's I and Getis Ord Gi*\n",
    "elots.to_file(\"J:\\Shared drives\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\estmonth_April14.geojson\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c918e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noOutlots, noOutlist = remove_outliers(elots, postSAdf,cluster_outlier_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94be7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distmatrix, noOutlist = euclidean_matrix(noOutlots,all_tazs,K,tps,noOutlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "beb174ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>id</th>\n",
       "      <th>taz</th>\n",
       "      <th>type</th>\n",
       "      <th>town</th>\n",
       "      <th>state</th>\n",
       "      <th>town_state</th>\n",
       "      <th>mpo</th>\n",
       "      <th>in_brmpo</th>\n",
       "      <th>subregion</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalNN</th>\n",
       "      <th>MR_SumNN</th>\n",
       "      <th>MR_Avg_NN</th>\n",
       "      <th>MR_Avg_NN_2010</th>\n",
       "      <th>DR_SumNN</th>\n",
       "      <th>DR_Avg_NN</th>\n",
       "      <th>DR_Avg_NN_2010</th>\n",
       "      <th>HR_SumNN</th>\n",
       "      <th>HR_Avg_NN</th>\n",
       "      <th>HR_Avg_NN_2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2571</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>BRIDGEWATER</td>\n",
       "      <td>MA</td>\n",
       "      <td>BRIDGEWATER,MA</td>\n",
       "      <td>OCPC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4448.326187</td>\n",
       "      <td>278.020387</td>\n",
       "      <td>191.834067</td>\n",
       "      <td>322.0000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>13.886250</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>7.375000</td>\n",
       "      <td>5.088750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2669</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>MA</td>\n",
       "      <td>HALIFAX,MA</td>\n",
       "      <td>OCPC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4977.319168</td>\n",
       "      <td>311.082448</td>\n",
       "      <td>214.646889</td>\n",
       "      <td>372.0000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>16.042500</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>8.937500</td>\n",
       "      <td>6.166875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4392</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>MIDDLEBOROUGH</td>\n",
       "      <td>MA</td>\n",
       "      <td>MIDDLEBOROUGH,MA</td>\n",
       "      <td>SRPEDD</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5402.213885</td>\n",
       "      <td>337.638368</td>\n",
       "      <td>232.970474</td>\n",
       "      <td>359.0958</td>\n",
       "      <td>22.443487</td>\n",
       "      <td>15.486006</td>\n",
       "      <td>154.632834</td>\n",
       "      <td>9.664552</td>\n",
       "      <td>6.668541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2641</td>\n",
       "      <td>49</td>\n",
       "      <td>I</td>\n",
       "      <td>MARSHFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>MARSHFIELD,MA</td>\n",
       "      <td>BRMPO</td>\n",
       "      <td>1</td>\n",
       "      <td>SSC</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5505.562979</td>\n",
       "      <td>344.097686</td>\n",
       "      <td>237.427403</td>\n",
       "      <td>373.0000</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>16.085625</td>\n",
       "      <td>166.160465</td>\n",
       "      <td>10.385029</td>\n",
       "      <td>7.165670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2643</td>\n",
       "      <td>50</td>\n",
       "      <td>I</td>\n",
       "      <td>MARSHFIELD</td>\n",
       "      <td>MA</td>\n",
       "      <td>MARSHFIELD,MA</td>\n",
       "      <td>BRMPO</td>\n",
       "      <td>1</td>\n",
       "      <td>SSC</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5392.975243</td>\n",
       "      <td>337.060953</td>\n",
       "      <td>232.572057</td>\n",
       "      <td>373.0000</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>16.085625</td>\n",
       "      <td>154.888794</td>\n",
       "      <td>9.680550</td>\n",
       "      <td>6.679579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>5835</td>\n",
       "      <td>4793</td>\n",
       "      <td>5834</td>\n",
       "      <td>I</td>\n",
       "      <td>TRURO</td>\n",
       "      <td>MA</td>\n",
       "      <td>TRURO,MA</td>\n",
       "      <td>CCC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>5836</td>\n",
       "      <td>4795</td>\n",
       "      <td>5835</td>\n",
       "      <td>I</td>\n",
       "      <td>TRURO</td>\n",
       "      <td>MA</td>\n",
       "      <td>TRURO,MA</td>\n",
       "      <td>CCC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>5837</td>\n",
       "      <td>4794</td>\n",
       "      <td>5836</td>\n",
       "      <td>I</td>\n",
       "      <td>PROVINCETOWN</td>\n",
       "      <td>MA</td>\n",
       "      <td>PROVINCETOWN,MA</td>\n",
       "      <td>CCC</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>5838</td>\n",
       "      <td>209094</td>\n",
       "      <td>5837</td>\n",
       "      <td>E</td>\n",
       "      <td>KILLINGLY</td>\n",
       "      <td>CT</td>\n",
       "      <td>KILLINGLY,CT</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>5839</td>\n",
       "      <td>209004</td>\n",
       "      <td>5838</td>\n",
       "      <td>E</td>\n",
       "      <td>DOVER</td>\n",
       "      <td>NH</td>\n",
       "      <td>DOVER,NH</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4330 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OBJECTID      id   taz type           town state        town_state  \\\n",
       "1            2    2571     1    I    BRIDGEWATER    MA    BRIDGEWATER,MA   \n",
       "2            3    2669     2    I        HALIFAX    MA        HALIFAX,MA   \n",
       "3            4    4392     3    I  MIDDLEBOROUGH    MA  MIDDLEBOROUGH,MA   \n",
       "4            5    2641    49    I     MARSHFIELD    MA     MARSHFIELD,MA   \n",
       "5            6    2643    50    I     MARSHFIELD    MA     MARSHFIELD,MA   \n",
       "...        ...     ...   ...  ...            ...   ...               ...   \n",
       "5834      5835    4793  5834    I          TRURO    MA          TRURO,MA   \n",
       "5835      5836    4795  5835    I          TRURO    MA          TRURO,MA   \n",
       "5836      5837    4794  5836    I   PROVINCETOWN    MA   PROVINCETOWN,MA   \n",
       "5837      5838  209094  5837    E      KILLINGLY    CT      KILLINGLY,CT   \n",
       "5838      5839  209004  5838    E          DOVER    NH          DOVER,NH   \n",
       "\n",
       "         mpo  in_brmpo subregion  ...  TotalNN     MR_SumNN   MR_Avg_NN  \\\n",
       "1       OCPC         0      None  ...     16.0  4448.326187  278.020387   \n",
       "2       OCPC         0      None  ...     16.0  4977.319168  311.082448   \n",
       "3     SRPEDD         0      None  ...     16.0  5402.213885  337.638368   \n",
       "4      BRMPO         1       SSC  ...     16.0  5505.562979  344.097686   \n",
       "5      BRMPO         1       SSC  ...     16.0  5392.975243  337.060953   \n",
       "...      ...       ...       ...  ...      ...          ...         ...   \n",
       "5834     CCC         0      None  ...     16.0     0.000000    0.000000   \n",
       "5835     CCC         0      None  ...     16.0     0.000000    0.000000   \n",
       "5836     CCC         0      None  ...     16.0     0.000000    0.000000   \n",
       "5837    None         0      None  ...     16.0     0.000000    0.000000   \n",
       "5838    None         0      None  ...     16.0     0.000000    0.000000   \n",
       "\n",
       "      MR_Avg_NN_2010  DR_SumNN  DR_Avg_NN  DR_Avg_NN_2010    HR_SumNN  \\\n",
       "1         191.834067  322.0000  20.125000       13.886250  118.000000   \n",
       "2         214.646889  372.0000  23.250000       16.042500  143.000000   \n",
       "3         232.970474  359.0958  22.443487       15.486006  154.632834   \n",
       "4         237.427403  373.0000  23.312500       16.085625  166.160465   \n",
       "5         232.572057  373.0000  23.312500       16.085625  154.888794   \n",
       "...              ...       ...        ...             ...         ...   \n",
       "5834        0.000000    0.0000   0.000000        0.000000    0.000000   \n",
       "5835        0.000000    0.0000   0.000000        0.000000    0.000000   \n",
       "5836        0.000000    0.0000   0.000000        0.000000    0.000000   \n",
       "5837        0.000000    0.0000   0.000000        0.000000    0.000000   \n",
       "5838        0.000000    0.0000   0.000000        0.000000    0.000000   \n",
       "\n",
       "      HR_Avg_NN  HR_Avg_NN_2010  \n",
       "1      7.375000        5.088750  \n",
       "2      8.937500        6.166875  \n",
       "3      9.664552        6.668541  \n",
       "4     10.385029        7.165670  \n",
       "5      9.680550        6.679579  \n",
       "...         ...             ...  \n",
       "5834   0.000000        0.000000  \n",
       "5835   0.000000        0.000000  \n",
       "5836   0.000000        0.000000  \n",
       "5837   0.000000        0.000000  \n",
       "5838   0.000000        0.000000  \n",
       "\n",
       "[4330 rows x 23 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar = knn_average(tps,noOutlots,distmatrix,noOutlist, all_tazs)\n",
    "tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887ffe9",
   "metadata": {},
   "source": [
    "# Calculate Average Rates per TAZ\n",
    "### Post Local Spatial Autocorrelation (Local Moran's I)\n",
    "The data is clustered - see versions of this analysis with Spatial Autocorrelation included for information on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "172c8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(lots, postSA, cof):\n",
    "    # if importing new data to add to lots, add and delete outliers\n",
    "    if isinstance(postSA, gpd.GeoDataFrame) and (len(cof) > 0): # if importing new data with LM outliers\n",
    "        postSA = postSA.to_crs(26986)\n",
    "        estmonth = lots.sjoin_nearest(postSA[[cluster_outlier_field+s for s in tps]+[\"geometry\"]], how=\"left\")\n",
    "        \n",
    "        # 1 and 13 are very close to each other (see index_right) removing them so can filter later\n",
    "        estmonth = estmonth[~estmonth.index.duplicated(keep='first')]\n",
    "        \n",
    "        # get lot ids where HL or LH for each time period and exclude them from the weighted average\n",
    "        inin =[]\n",
    "        for x in tps:\n",
    "            inin.append(estmonth[~estmonth[cof+x].isin([\"LH\", \"HL\"])].reset_index()['index']) \n",
    "    return estmonth, inin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adb6afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_matrix(lots,tazs,K,tps,inin=[]):\n",
    "\n",
    "    estmonth = copy.deepcopy(lots)\n",
    "    if len(inin) == 0:\n",
    "        for x in tps:\n",
    "            inin.append(estmonth.reset_index['index'])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # get euclidean distance matrix from TAZ centroids to lots\n",
    "    # also reproject to Mass State Plane (meters) so that distance is correct\n",
    "    rdg83 = alltazs.to_crs(\"EPSG:26986\").set_index(\"id\") # TAZ ids are now the column names\n",
    "    eucdist = estmonth.centroid.geometry.apply(lambda g: rdg83.distance(g))\n",
    "    # convert to miles\n",
    "    eucdistmi = eucdist/1609.34\n",
    "    \n",
    "    # get just closest 16 lots to each TAZ centroid based on euclidean distance\n",
    "    numlot = len(eucdistmi)\n",
    "    for col in eucdistmi.columns:\n",
    "        big = max(eucdistmi[col].nsmallest(K))\n",
    "        eucdistmi.loc[eucdistmi[col] > big, col]= np.nan\n",
    "\n",
    "    # set distances (weights) to 1 so all have equal weights\n",
    "    eucdistmi[eucdistmi.notna()] = 1\n",
    "    \n",
    "    return eucdistmi, inin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d979d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_average(tps, estmonth, eucdistmi, inin, tazs):\n",
    "    # tazs & lots to filter\n",
    "    tazids = tazs[(tazs['town'].isin([\"BOSTON\",\"CAMBRIDGE\",\"SOMERVILLE\",\n",
    "                                        \"BROOKLINE\",\"NEWTON\"])) & (tazs['id'] < 200000)][\"id\"].tolist()\n",
    "\n",
    "    # multiply weights (1) by rates, reminder: weights are all 1 so this is essentially a mask\n",
    "    # filter the rates and weights by whether the lot is an outlier, then multiply\n",
    "    msums = []\n",
    "    for z in tps:\n",
    "        g = estmonth[z+'_wEst2'].filter(items = inin[tps.index(z)], axis=0)\n",
    "        m = eucdistmi.filter(items = inin[tps.index(z)], axis=0).multiply(g, axis=\"index\")\n",
    "        msum = m.sum()\n",
    "        msum.name = z+\"_SumNN\"\n",
    "        #save so can merge together later\n",
    "        msums.append(msum)\n",
    "        \n",
    "    #sum weights by TAZ\n",
    "    wsum = eucdistmi.sum() # should be K from KNN\n",
    "    wsum.name = \"TotalNN\"\n",
    "    \n",
    "    # join weighted rates sums by taz and sum weights by taz together\n",
    "    for q in msums:\n",
    "        wsum = pd.merge(wsum,q, left_index=True, right_index=True)\n",
    "        wsum[q.name] = np.where(~wsum.index.isin(tazids), 0, wsum[q.name])\n",
    "        wsum[q.name.split(\"_\")[0]+\"_Avg_NN\"] = wsum[q.name]/wsum[\"TotalNN\"]\n",
    "        \n",
    "        # Convert to 2010\n",
    "        wsum[q.name.split(\"_\")[0]+\"_Avg_NN_2010\"] = wsum[q.name.split(\"_\")[0]+\"_Avg_NN\"] * 0.69\n",
    "        \n",
    "    # final spatial result    \n",
    "    tazs_avg_rates = pd.merge(tazs,wsum, left_index=True, right_index=True)\n",
    "    \n",
    "    return tazs_avg_rates\n",
    "    #return wsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60944f",
   "metadata": {},
   "source": [
    "# Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58878839",
   "metadata": {},
   "outputs": [],
   "source": [
    "tazs_avg_rates.drop(\"geometry\",axis=1).to_csv(\"J:\\\\Shared drives\\\\TMD_TSA\\\\Data\\\\Parking\\\\WebScraped_ParkingCost\\\\tazs_avg_rates2010_Apr21.csv\")\n",
    "\n",
    "tazs_avg_rates.to_file(\"J:\\Shared drives\\\\TMD_TSA\\Data\\Parking\\WebScraped_ParkingCost\\\\tazs_avg_ratesApr21.geojson\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04902ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_knn_average_per_taz(tps, tazs, lots,K=16, postSA=\"\",cof=\"\"):\n",
    "    lots = lots.to_crs(26986)\n",
    "    \n",
    "    ### PART 1\n",
    "    # if importing new data to add to lots, add and delete outliers if present\n",
    "    if isinstance(postSA, gpd.GeoDataFrame) and (len(cof) > 0): # if importing new data with LM outliers\n",
    "        postSA = postSA.to_crs(26986)\n",
    "        lots = lots.drop(columns=[\"index_right\"])\n",
    "        estmonth = lots.sjoin_nearest(postSA[[[cof+s for s in tps],\"geometry\"]], how=\"left\")\n",
    "        \n",
    "        # 1 and 13 are very close to each other (see index_right) removing them so can filter later\n",
    "        estmonth = estmonth[~estmonth.index.duplicated(keep='first')]\n",
    "        \n",
    "        # get lot ids where HL or LH for each time period and exclude them from the weighted average\n",
    "        inin =[]\n",
    "        for x in tps:\n",
    "            inin.append(estmonth[~estmonth[cof+x].isin([\"LH\", \"HL\"])].reset_index()['index'])        \n",
    "        \n",
    "    else: #just put it to the same name if not reimporting\n",
    "        estmonth = copy.deepcopy(lots)\n",
    "        inin=[]\n",
    "        for x in tps:\n",
    "            inin.append(estmonth.reset_index['index'])\n",
    "    \n",
    "    ### PART 2\n",
    "    # get euclidean distance matrix from TAZ centroids to lots\n",
    "    # also reproject to Mass State Plane (meters) so that distance is correct\n",
    "    rdg83 = alltazs.to_crs(\"EPSG:26986\").set_index(\"id\") # TAZ ids are now the column names\n",
    "    eucdist = estmonth.centroid.geometry.apply(lambda g: rdg83.distance(g))\n",
    "    # convert to miles\n",
    "    eucdistmi = eucdist/1609.34\n",
    "    \n",
    "    # get just closest 16 lots to each TAZ centroid based on euclidean distance\n",
    "    numlot = len(eucdistmi)\n",
    "    for col in eucdistmi.columns:\n",
    "        big = max(eucdistmi[col].nsmallest(K))\n",
    "        eucdistmi.loc[eucdistmi[col] > big, col]= np.nan\n",
    "\n",
    "    # set distances (weights) to 1 so all have equal weights\n",
    "    eucdistmi[eucdistmi.notna()] = 1\n",
    "    \n",
    "    # tazs & lots to filter\n",
    "    tazids = tazs[(tazs['town'].isin([\"BOSTON\",\"CAMBRIDGE\",\"SOMERVILLE\",\n",
    "                                        \"BROOKLINE\",\"NEWTON\"])) & (tazs['id'] < 200000)][\"id\"].tolist()\n",
    "    \n",
    "    ### PART 3\n",
    "    # multiply weights (1) by rates\n",
    "    # filter the rates by whether the lot is an outlier - so will match weights below\n",
    "    # filter the weights by whether the lot is an outlier, then multiply by rates\n",
    "    # reminder: weights are all 1 so this is essentially a mask\n",
    "    msums = []\n",
    "    for z in tps:\n",
    "        g = estmonth[tps[z]+'_wEst2'].filter(items = inin[z], axis=0)\n",
    "        m = eucdistmi.filter(items = inin[z], axis=0).multiply(g, axis=\"index\")\n",
    "        msum = m.sum()\n",
    "        msum.name = [tps[z]+\"SumNN\"]\n",
    "        #save so can merge together later\n",
    "        msums.append(msum)\n",
    "        \n",
    "    #sum weights by TAZ\n",
    "    wsum = eucdistmi.sum() # should be K from KNN\n",
    "    wsum.name = [\"TotalNN\"]\n",
    "    \n",
    "    # join weighted rates sums by taz and sum weights by taz together\n",
    "    for q in msums:\n",
    "        wsum = pd.merge(wsum,q, left_index=True, right_index=True)\n",
    "        wsum = np.where(~wsum.index.isin(tazids), 0, wsum[q.name])\n",
    "        wsum[q.name.split(\"SumNN\")+\"_Avg_NN\"] = wsum[q.name]/wsum[\"TotalNN\"]\n",
    "        \n",
    "        # Convert to 2010\n",
    "        wsum[q.name.split(\"SumNN\")+\"_Avg_NN_2010\"] = wsum[q.name.split(\"SumNN\")+\"_Avg_NN\"] * 0.69\n",
    "        \n",
    "    # final spatial result    \n",
    "    tazs_avg_rates = pd.merge(tazs,wsum, left_index=True, right_index=True)\n",
    "    \n",
    "    return tazs_avg_rates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geostat] *",
   "language": "python",
   "name": "conda-env-geostat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
